#  一：万物皆可对象

* Java中的基本类型，不是动态内存分配，而是静态分配在栈中。（类似于C，C++）
  基本类型具有包装器类，使得可以在堆中创建一个非基本对象，用来表示对应的基本对象。

```java
char c = 'x';
Character ch = new Character(c);
或者
Character ch = new Character('x');
```

* java基本成员初始化只针对某个类的成员变量，不针对局部变量（即并非类的变量）。

* java方法只能作为类的一部分来创建，方法只能通过对象来调用

  ​		tips：static方法是针对类调用的，并不依赖对象的存在。

* 参数传递的也是对象的引用。（基本类型是例外）

* java.lang默认导入到每个java文件。

* 对象在堆中的结构：

  * **对象头**
    * **mark word：存储着与当前对象运行时的状态信息（最后一位就是锁标志位）**
    * **class point：一个指针，指向了当前对象类型在方法区中的数据**
  * **实例数据**
  * **填充字段**
  
* **三大特性：**

  *  **封装：隐藏对象的属性和内部细节，仅仅对外公开接口**

    * 便于使用者正确方便地使用系统，防止权限越界或错误修改系统属性
    * 有助于建立系统各个模块间的松耦合关系
    * 有助于提高系统可重用性
    * 有助于降低系统整体风险，即时某个小模块出问题，对外界的影响也会降到最低。

  *  **继承：子类继承父类的属性和行为，并根据需要拓展出自己所需的新的属性和行为，提高重用性。**

  *  **多态：同一个动作在不同的使用方式下具有多个不同表现形式或形态。（也就是说同一个接口，不同使用方法可以进行不同的操作）**

    **多态的条件：**

    * 继承
    * 重写
    * 父类引用子类对象
  
* **父类引用指向子类对象（多态的必要条件之一）**

  * 引用只能调用父类中定义的方法和变量
  * 如果子类中重写了父类中的一个方法，那么在调用这个方法的时候，将会调用子类中的这个方法（**动态连接、动态调用**）

* **覆盖和隐藏：**

  * **隐藏** ：子类隐藏了父类的变量和静态方法，那么，子类不能访问父类被隐藏的变量或者静态方法，但是，将子类强制转型为父类后（或者说**父类引用指向子类对象时**），可以访问父类中被隐藏的变量或者静态方法
  * **覆盖** ：子类覆盖了父类的实例方法，那么，子类不能访问父类被覆盖实例方法，将子类转换成父类后同样不能访问父类被覆盖的实例方法

  子类对象转换成父类对象后，**隐藏消失**，即能够访问父类被隐藏的变量和静态方法，**覆盖不消失**，即而不能访问父类被覆盖的方法。

  如果子类要访问父类覆盖的方法，可以使用super关键字。

  * **被隐藏的属性，在子类被强制转换成父类后，访问的是父类中的属性（隐藏消失）**

  * **被覆盖的方法，在子类被强制转换成父类后，调用的还是子类自身的方法（覆盖不消失）**
  * **也就是说：当发生隐藏的时候，声明类型是什么类，就调用对应类的属性或者方法，而不会发生动态绑定**

  |      |          隐藏          |         覆盖         |     能否交叉      |
  | :--: | :--------------------: | :------------------: | :---------------: |
  | 变量 |       只能被隐藏       |      不可被覆盖      |   可以交叉隐藏    |
  | 方法 | 只有static方法能被隐藏 | 只有实例方法能被覆盖 | 不能交叉隐藏/覆盖 |

* **静态绑定（非动态绑定、不可被覆盖重写）的方法：**

1. Static（可以被继承，但是无法被重写，可以重载，只能隐藏）
  2. Final（可以被继承，但是无法被重写）
  3. 构造函数
  4. private（因为不可被继承，所以不可被重写）

# 二：语法

* ```java
        Integer[] A = new Integer[10];
    
          Arrays.sort(A, new Comparator<Integer>(){
         public int compare(Integer a, Integer b)
          {
            return a-b;
          }
          });
  ```
  
* **foreach语法：**

  ```java
  for(int i : A)
  for(char c : C)
  for(int i : range(5, 10, 2))
  ```
  
* a减b的绝对值：

    ```java
    Math.abs(a-b);
    ```

* java中，int为4个字节，char为两个字节，所以可以将char隐式的转换为int，但是将int转换为char时，可能会出现数据丢失，此时需要用到强制转换。

    ```java
    char ch = 97
    
    int i = ch
    
    char c = (char) i 
    ```

* **循环嵌套（标签存在的唯一理由）：**

  *   break
    * 普通的break只是结束当前循环
    * 带标签的break会立即中断以及跳出标签所指的循环
  *   continue
      *   普通的continue只会退回当前循环的开头，并继续执行
      *   带标签的continue会跳到标签处，并重新进入标签后的那个循环
  
* **如果重载了构造方法但是又没有重载空参数构造方法，则在使用空参数构造方法时将会报错，因为之前那个空参数构造方法已经不复存在了。**
  例如：
  
  ```java
  A a == new A(23); // 这里表明已经重载了构造方法但是全都有参数
  A a == new A(); // 紧接着执行这条代码将会报错
  ```
  
* **hashcode（）**

  * ```java
    public native int hashCode();
    ```
    
  * Java中：

       **如果x.equals(y)返回“true”，那么x和y的hashCode()必须相等。**

       **如果x.equals(y)返回“false”，那么x和y的hashCode()有可能相等，也有可能不等。**
       
  * 在hashmap或者hashtable、hashset中，先通过hashcode ()方法计算对象的hashcode值，通过这个hashcode值在hashmap中存放的一个table中找到应该存放的位置，若该hashcode未存在，则直接在指定位置添加该新元素，若该hashcode已存在，则用equals()方法将新元素和已存在的元素进行比较，若存在一个老元素和新元素相匹配，则覆盖，否则添加新元素。

  * **虽然不能根据hashcode判断两个对象相等，但是可以通过它判断两个对象不等。**

  * **如果重写了equals()方法，则必须要重写hashCode()方法。否则可能会出现equals()方法返回True，但hashcode()方法判断不等的情况。**

  * 在程序执行期间，只要equals方法的比较操作用到的信息没有被修改，那么对这同一个对象调用多次，hashCode方法必须始终如一地返回同一个整数。（也就是说hashcode() 方法依赖于对象中易变的数据是一件非常危险的事情）

* **==与equals()的区别**
  
  * ==
  
    **这是一个关系运算符**
  
    * 若比较的两者是基本类型，则比较它们的值是否相同
    * 若比较的两者是非基本类型，则比较的是它们的引用对象是否相同（指向的地址是否相同）
  
  * equals()
  
    **这是Object类的一个方法。**
  
    * 若未重写该方法，则比较的是引用的对象地址
    * 若像Integer，Double，String等类一样重写了该方法，则比较的是两者所指对象的内容
  
* **final 和 static的区别**
  
  * 成员变量
  
  final成员变量表示为一个常量，被初始化后就不能被改变。
  
  * 初始化方式：
    * 定义时直接赋值
    * 在构造代码块中为其赋值
    * 在构造函数中赋值
  
  static成员变量表示为一个“**静态变量**”，在内存中只有一份拷贝，可以被修改
  
  *  方法
  
    final方法不能被子类重写。（所以是静态绑定）
  
    static方法表示为一个静态方法，和静态变量一样不依赖于任何实例对象，被所有实例共享。
  
    * A，它们仅能调用其他的static 方法
  
    * B，它们只能访问static数据
  
    * C，它们不能以任何方式引用this 或super(**this涉及到对象，super 与继承有关**）
  
  * 类 
  
    static修饰类时只有一种情况：**静态内部类。**
  
    |          |       使用变量和方法       |           初始化           |
    | :------: | :------------------------: | :------------------------: |
    |  静态类  | 只能访问外部静态变量和方法 | 可以使用外部类名直接初始化 |
    | 非静态类 | 可以任意访问内外部变量方法 | 必须需要外部类的实例初始化 |
  
    final类不能被继承，不能被重写（覆盖）。**所以其中变量和方法的地址引用和装载在编译期间完成，而不是在运行期间由JVM进行复杂的装载，因而简单和有效**。**（静态绑定）**
  
    所以如果没有必要，或者不存在有继承的可能性时，尽量使用final类。
  
  * static代码块：在类被加载时执行一次，以初始化static变量。
  
# 三：容器

* 向一个A类型容器中可以任意加入A的子类型，但通过get方法拿出来时都被向上转型为A类型。

* 任何集合都继承于两个接口中的一个：

  * **Collection：一个独立的元素序列**

    ![这里写图片描述](https://img-blog.csdn.net/20180612094225630?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3poYW5ncXVuc2h1YWk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

    * **List（有序的，指的是存储的顺序与输入顺序相同）：**
      * ArrayList：底层为一个动态数组。随机存取快，删除插入慢
      * LinkedList： 底层为一个双向链表。随机存取慢，删除插入快
      * Vector：底层为一个动态数组，**但是使用了synchronized，保证了线程安全。**所以整体效率低于ArrayList。
    * **Set（不允许元素重复，且遍历出的顺序与输入顺序不同）：**
      * **HashSet：**基于**HashMap**实现，添加元素时，先通过hashcode判断有无相同元素，若存在hashcode相同的元素，则使用equals()方法判断是不是为同一元素，若相同，则添加失败，若不同，则添加元素。
      * **LinkedHashSet：**基于**LinkedHashMap**实现
      * **TreeSet：**基于TreeMap实现
    * Queue

  * **Map：一组成对的“键值对”对象**

    * **hashMap**：基于数组和链表的键值对存储结构。
      * **底层中，数组被分为一个个桶（bucket），每个桶里存储着一个或多个Node对象（实现了Entry接口），Node对象由键、值、指向下一个Node对象的指针。** 
      * **键的hashcode值对应着Node对象的hash属性值，也就决定了该Node在数组中的位置，**而每个bucket里面存放着的是所有hash值相同的Node对象的一个单链表。
      * **Node的hash值 = （key的hash值） ^ （key的hash值右移4位） （目的是使Node的hash值混合key的hash值高四位和低四位的信息，更有代表性。从而减少了hash碰撞的几率。同时在hashmap扩容时，会将Node的hash值与数组长度-1进行与运算，这样也使得原有的Node在新数组中分配的更均匀。）**
      * 通过数组下标检索Node的时间复杂度为O(1)，而链表遍历时的复杂度为O(n)，**所以在链表长度很长时，遍历链表的时间就会明显大于检索数组的时间，所以当链表长度大于8时，链表将会变为一个红黑树**，以减少检索时间（临界值为8的原因和泊松分布有关。底层数组的长度和hash碰撞的几率服从泊松分布，在LoadFactor——负载因子为0.75时最小）。
      * put()方法：先根据key的hash值确定在数组中的位置，判断该位置是否存在Node对象，若不存在，则直接添加该Node对象，若存在，则通过equals（）方法根据key值遍历链表，**若发现key相同的对象，则覆盖**，否则添加该新对象。
      * get()方法：现根据key的hash值确定在数组中的位置，遍历链表，通过equals()方法判断对象是否相等，若存在相等的，就返回。
      * **hashmap的线程安全问题：**hashmap用数组+链表。数组是固定长度，链表太长就需要扩充数组长度进行rehash减少链表长度。如果两个线程同时触发扩容，在移动节点时会导致一个链表中的2个节点相互引用，从而生成环链表。
      * 扩容：

* Set和Map容器都有基于哈希存储和排序树的两种实现版本:

  * **hashset、hashmap**:基于哈希存储的版本理论存取时间复杂度为O(1)
  * **treeset、treemap**:基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。理论存取，插入删除的时间复杂度为O(log n)

* **自己设计一个hashmap：**

  利用数组和链表。对于一个key，他的hash值通过hashcode（）来获取，由此来确定key在数组中的位置。插入数据时就把元素放到这个位置上，如果此位置已经有元素了（发生了hash冲突），就使用equals（）遍历链表，如果存在就覆盖，不存在就在链表末尾重新添加该元素就好了。查找时步骤和以上基本一样。
  
* **线程安全问题：**

  * hashmap，arraylist等容器都不是线程安全的，**因为add()源码中那句element[size++] = e;可以分为两句，**element[size] = e;size++;所以在多线程情况下，如果共用同一个容器，就会出现一个线程添加的值被另一个线程覆盖的情况。
  
  * 可以在创建容器实例的时候，对其加上Collections.synchronized修饰。（会大大影响其效率）.
  
    **Collections.synchronizedXxx()函数接收特定的Collection，将其转换成包装类型的SynchronizedXxx类型，对整个容器同步**
  
    ```java
    List list = new ArrayList();
    List synlist = Collections.synchronizedList(list);
    或者
    List synlist = Collections.synchronizedList(new ArrayList());
    ```
  
  * **也可以使用线程安全的集合类（比如ConcurrentHashMap）**，在此类容器内采用的是将这个空间分为多个Segment，每次对某个Segment进行写操作时，**都只对该Segment加锁**，不会对其他线程或者其他Segment产生影响，大大提高了效率。
  
  * Collections.synchronizedMap()与ConcurrentHashMap主要区别是：**Collections.synchronizedMap()和Hashtable一样，实现上在调用map所有方法时，**都对整个map进行同步**，**而ConcurrentHashMap的实现却更加精细，它对map中的所有桶加了锁**。所以，只要要有一个线程访问被Collections.synchronized修饰的map，其他线程就无法进入该map，而如果一个线程在访问ConcurrentHashMap某个桶时，其他线程，仍然可以对map执行某些操作。这样，ConcurrentHashMap在性能以及安全性方面，明显比Collections.synchronizedMap()更加有优势。同时，同步操作精确控制到桶**，所以，即使在遍历map时，其他线程试图对map进行数据修改，也不会抛出ConcurrentModificationException。
  
* iterator统一了对容器的访问方式：

  ```java
  ArrayList<Integer> A = new ArrayList<Integer>();
  
  Iterator B = A.iterator();
  ```

#### 四：线程

* 分类：**用户级线程（ULT），内核级线程（KLT）**

  * 内核级线程(KLT)：交给内核管理
    * 在线程切换时，会有内核态和用户态切换的过程，消耗大。速度比UTL慢。

  * 用户级线程(ULT)：交给用户应用管理
    * 不需要在内核态和用户态的切换，速度快。内核无感知。

* **线程的五种基本状态：**
  
  * 初始化状态（new）
    * 创建（new）了一个新的线程对象，但还没有调用start（）方法，则此时线程状态为初始化状态。
  * 可运行状态
    * 就绪状态：初始化状态下的线程调用了start（）方法，但还没有被调度程序分配CPU的使用权，此时处于就绪状态。
    * 运行时状态 ：当就绪状态下的线程获得了使用CPU的权限后，将进入该状态。**这是线程进入运行状态的唯一方式。**
  * 等待状态
    * 进入该状态的线程需要等待其他线程做出一些动作。
  * 超时等待状态
    * 和等待状态相似，但是可以在指定时间后自行返回。
  * 阻塞状态
    * 该状态表示线程在尝试获得对象锁时失败而进入的状态。**线程阻塞于锁。**
  * 结束状态
    * 当线程run（）方法执行结束后或主线程的main（）方法关闭后，该线程进入结束状态。
  
* wait()方法：
  
  * 当前线程调用对象的wait（）方法，交出该对象的锁，并暂时停止该线程的执行（交出CPU使用权），将该线程放入等待队列。
  
* notify()方法：
  
  * 当先线程
  
* **monitor机制（依赖于mutex lock操作）：**
  
  * monitor机制是基于操作系统的mutex lock操作实现的，使用monitor机制就是为了使线程能够互斥地进入临界区（**临界区就是被synchronized关键字修饰的方法、代码块**），在该机制中存在着等待队列和就绪队列用来存放等待线程和就绪线程，而由于monitor机制是基于mutex原语的，所以需要维护一个基于mutex的锁，那就是对象锁。
  * monitor只允许一个线程进入monitor，其他线程在Entry Set中等待（处于waiting状态）
  * 当一个线程A进入了monitor，就处于active状态
  * 假设A在执行时遇到了一个判断条件，使得A需要让出执行权，则A进入wait Set，状态被改为waiting状态
  * 此时Entry Set中的线程B成功进入monitor，那么B可以通过notify来唤醒线程A
  * 在B执行结束后，A就重新有机会获得进入monitor的机会（A进入了Entry Set）
  * **注意：由于monitor机制是基于操作系统的mutex机制，所以在线程的挂起和唤醒时，都会切换操作系统的内核态和用户态，这种操作是重量级的，会消耗大量的资源和时间。**
  
* **对象锁**：**在每个object对象中，都有一把锁，存放在方法区对象的对象头中，里面描述了该对象被哪个线程占用。**
  
* **synchronized机制（依赖于monitor机制）：**
  
  * **synchronized修饰词被编译成字节码后就是：monitorenter和monitorexit两条字节码**，两条字节码对synchronized业务代码进行包裹。
  * 代码块： 
    * 当两个并发线程同时执行到同一个对象的synchronized代码块时，只能有一个线程取得该对象的对象锁，其他对象由于得不到对象锁，只能等待。
    * 当一个线程访问该对象的synchronized代码块时，其他线程依然可以访问该对象的非synchronized代码块。
  
* 锁：
  
  * **无锁：**在不存在竞争或者不想用锁机制实现并发时，可设置为无锁（此时可以使用CAS方式进行线程的并发同步）。
  * **偏向锁：**指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。其目标就是在只有一个线程执行同步代码块时能够提高性能。
  * **轻量级锁：**是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，**不会阻塞，**从而提高性能。
  * **重量级锁：**若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁，**此时线程会被阻塞**。
  * **悲观锁：**认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。**悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。**
  * **乐观锁：**认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。**乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。**
  
* 线程实现方式：
  
  * **继承Thread类**
    
    * 定义一个继承Thread类的类
    * 重写run（）方法
    * 实例化对象
    * 调用start（）方法
    
  * **实现Runnable接口**
    
    * 实现Runnable接口
    * 重写run（）方法
    * 实例化对象
    * 创建Thread对象，并将自定义类对象作为构造方法参数
    * 调用Thread对象的start（）方法
    
  * 实现Callable接口
  
  * 使用线程池**（ThreadPoolExecutor类）**
    
    * 原理就是提前创建出一定数量的线程放入池中，每当要使用线程的时候，从池中直接拿取，每当使用完毕后，再放回池中。这样就避免了频繁地创建、销毁线程，大大节约了系统开销。
    
    * ```java
      ExecutorService service = Executors.newFixedThreadPool(10);
      new ThreadPoolExecutor()
      
      service.execute(new NumberThread());//NumberThread类实现了Runnable接口
      service.submit(new NumberThread());//NumberThread类实现了Callable接口
      
      service.shutdown();
      ```
      
    * 需要实现Runnable接口或者实现Callable接口的对象，将其作为Executor对象方法的参数。其中：
      
      * Runnable类：execute（）方法
      * Callable类：submit（）方法
      
    * **提高响应速度（减少了创建新线程的时间）**
    
    * **降低资源消耗（重复利用线程池中的线程，不需要每次都创建）；**
    
    * **便于线程管理**
    
    * **四个核心参数：**
    
      * corePoolSize 线程池核心线程大小
    
        线程池所维护的最小线程数量。在新线程池创建时，其中的线程数为0，除非调用了线程池的预创建线程函数，
    
        注意：
    
        * **只要创建了，即使这些核心线程处于空闲状态，也不会被销毁。**
        * **当线程数小于核心线程数时，即时有空闲状态的线程，也会优先创建线程执行任务。**
      
      *  maximumPoolSize 线程池最大线程数量
      
      线程池所允许的最大线程数量
      
      *  keepAliveTime 空闲线程存活时间
      
        如果一个存在线程处于空闲状态，且线程数大于核心线程数，那么在指定时间后，该线程将会被销毁。
      
      *  workQueue 工作队列**（阻塞队列）**
      
        当新任务被提交后，会先到工作队列中。
      
    * **原理细节，当一个新任务到达时：**
    
      * 若工作线程数小于核心线程数，则会创建一个线程执行任务。
      * 若线程数 >= 核心线程数，且工作队列未满，则将任务添加在工作队列中，等待。
      
      * 若工作队列满了，则新创建一个工作线程执行队列中第一个任务。
      * 若线程数已经等于最大线程数，则执行饱和策略。
      
    * **四种队列：**
    
      * **基于数组的有界队列**
      * **基于链表的无界队列：**有新任务到达时，会直接存入该队列，不会去创建新线程执行任务（可以理解为该队列永远不会满）
      
      *  **不缓存任务的队列：**若有新任务到达，会直接建立线程执行。（可以理解为这种队列的大小为0）
      *  **具有优先级的队列**
      
    * **四种饱和策略：**
    
      * **AbortPolicy：**直接丢弃任务，抛出异常。
      * **CallerRunsPolicy：**直接让调用者所在线程来运行任务。
      
      * **DiscardOldestPolicy：**丢弃队列里最近的一个任务，并执行当前任务。
      * **DiscardPolicy：**直接丢弃任务，但不抛出异常。
      
    * **四种线程池：**
    
      * newSingleThreadExecutor：单线程化的线程池
    
        保证任务按照指定顺序执行**（核心线程数和最大线程数为1，采用无界队列）**
    
      * newFixedThreadPool：定长线程池
    
        可控制线程最大并发数，如果池中满了，新线程将会在队列中等待**（核心线程数和最大线程数为一个大于1的值，采用无界队列）**
    
      * newScheduledThreadPool：可定期或延时执行的线程池
    
        支持定时及周期性任务执行**（核心线程数为一定值，最大线程数为无穷大，线程生存时间为0）**
    
      * newCachedThreadPool：可缓存线程池
    
        如果线程池长度过长（超过需要），可以回收空闲线程，若不足，则可新建线程。（较为灵活）（**核心线程数为0，最大线程数为无穷大，采用直接执行不缓存队列，线程生存时间为60s**）
      
    * 线程数的配置方案：
    
      * CPU密集型：建议线程数为CPU核心数的1~2倍，因为过多的线程数会造成频繁的线程切换，造成不必要资源浪费
      * IO密集型：建议线程数为CPU核心数的很多倍。因为IO操作耗费的时间比较长，如果线程数过少，会导致CPU长时间处于等待IO结束的状态，造成时间上的浪费。
#### 五：JVM

* **编译器：** 

  将源文件编译成字节码文件（.class文件）。比如：**javac.exe**

* **解释器：**

  将字节码文件翻译成与本地平台相关的机器代码的中间代码，然后执行。比如：**java.exe**

* **即时编译器JIT：**

  **由于解释器时一行一行的解释执行**，所以当JVM发现某些代码经常被重复执行时（例如：循环代码、被多次调用的方法），JIT就会将这些代码直接编译为适合本机机器的原生机器码，进行缓存然后执行。这样，对于频繁被执行的某些代码，JVM可以以极快的速度执行它们。（注意：**只有对频繁执行的代码，JIT编译才能保证有正面的收益，因为JIT将字节码编译为原生机器码的一次过程依然比解释器解释执行的一次过程要慢。**）

* 基本结构：

  * **程序计数器（PC）：字节码指令的地址，线程私有的。JVM中唯一一片不会发生内存泄漏的区域。**

  * **虚拟机栈：常见的栈结构，主要用于方法调用**

    存放**局部变量、操作数栈、帧数据区、传入参数、方法出口**等，是**线程私有**的，生命周期和线程一致。

    * 1、只有在调用一个方法时，才为当前栈分配一个帧，然后将该帧压入栈。

      2、帧中存储了对应方法的局部数据，方法执行完，对应的帧则从栈中弹出，并把返回结果存储在调用方法（父方法）的帧的操作数栈中。

    * **StackOverflowError：**线程请求的栈深度大于虚拟机允许的深度。
    * **OutOfMemoryError：**若栈中没有内存可供申请空间，则抛出异常。

  * **堆：实例对象和数组加载的空间。**

    存放对象实例和数组，**线程共享，物理上不连续，但逻辑上连续。**

    * **OutOfMemoryError：**若堆中没有内存完成可供分配实例，则抛出该异常。

  *  **本地方法栈：只执行native方法。**

  *  **方法区：**

    是各个**线程共享**的内存区域，它用于存储**已被虚拟机加载的类信息、常量、静态变量（注意：实例变量是存放在堆中的！！！！）、即时编译器编译后的代码等数据**。

    * 大小不必固定，可动态分配，不必连续，也可指定初始大小和最大最小尺寸。
  * 包含**运行时常量池：存放一些在运行时创建的一些常量**

* GC垃圾回收机制 

  * 可以有效地防止内存泄漏，有效地使用空闲内存。
  * 所有垃圾回收机制都包含两个算法：**（1）发现无用信息对象；（2）回收被无用对象占用的内存空间，使该空间可被程序再次使用。**
    * **判断一个对象是否为垃圾（是否已死）算法：**
      * **引用计数器算法**：为每个对象设置一个计数器，当一个对象被引用时，计数器加一，当引用失效时，计数器减一，当计数器为0时，则判断为一个垃圾对象。**实现简单，效率高，但是存在循环引用问题。**
      * **可达性分析算法：**一种根搜索方法，从一个GC Root对象开始，向下搜索对应的引用节点，找到节点后又继续寻找该节点的引用结点，当所有的引用结点都找完之后，剩下的没有通向GC Root的引用链的对象都被认作为垃圾对象。
      * **可作为GC Root的对象：**
        * 虚拟机栈中引用的对象
        * 方法区中静态属性引用的对象
        * 方法区中常量引用的对象
        * 本地方法栈中引用的native对象
    * **如何回收垃圾（垃圾回收算法）：**
      * **标记-清除算法：**
        * 标记阶段：标记出需要被回收的对象。
        * 清除阶段：回收被标记的可回收对象的内存空间。
        * 算法执行时需要暂停整个应用，并且清除之后不会对内存空间进行整合，会造成大量的不连续内存碎片，并且由于不连续，标记和清除的耗时也非常大。
      * **复制算法：**
        * 复制算法将可用内存分为两块，每次只用其中一块，另外一块作为预留区域，当执行算法时，就将还存活着的对象复制到预留区域中，然后再把已经使用过的内存空间一次性清理掉，这片区域又作为新的预留区域。
        * 简单，不易产生内存碎片，但是每次都将一半的内存作为预留区域，内存的使用率会更低。
      * **标记-整理算法：**
        * 该算法标记阶段和“标志-清除”算法一样，但是在完成标记之后，它不是直接清理可回收对象，而是将存活对象都向一端移动，**然后清理掉端边界以外的内存。**
      * 分代垃圾回收
        * 核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。
        * 年轻代：特点是每次垃圾回收时都有大量的对象被回收
          * eden区：对象的生成都在eden区中，当一次垃圾回收执行时，先将该部分中的存活对象放入survivor0区中，然后清空eden区。
          * survivor区：
            * survivor0区：
            * survivor1区：
        * 老年代：特点是每次垃圾回收时只有少部分对象被回收
      * 
  * 

* 在实际开发中，我们对 `new` 出来的对象也会根据重要程度，有个等级划分。有些必须用到的对象，我们希望它在其被引用的周期内能一直存在；有些对象可能没那么重要，当内存空间还足够时，可以保留在内存中，如果内存空间在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。

  **引用的四种类型**：

* 


​      